{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a multi-lingual model locally (Mac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "WORKING_DIR = \"ml-training/SECRECY-EN/\"\n",
    "TARGET_LANG = \"en\"\n",
    "TEST_LANG = \"en\" if TARGET_LANG == \"es\" else \"es\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "en_train = pd.read_csv(\"ml-training/SECRECY-EN/en_secrecy_train_audited_smart_downsampled.csv\")\n",
    "en_test = pd.read_csv(\"ml-training/SECRECY-EN/en_secrecy_test_audited.csv\")\n",
    "es_test = pd.read_csv(\"ml-training/SECRECY-EN/es_secrecy_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO DOWNSAMPLING\n",
    "# training set has already been downsampled (keeping hard negatives)\n",
    "# test set will not be downsampled\n",
    "en_train_neg = en_train[en_train.label == 0]#.sample(frac=0.1, replace=False)\n",
    "en_test_neg = en_test[en_test.label == \"no\"]#.sample(frac=0.05, replace=False)\n",
    "es_test_neg = es_test[es_test.label == 0]#.sample(frac=0.05, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train = pd.concat([en_train_neg, en_train[en_train.label != 0]])\n",
    "en_test = pd.concat([en_test_neg, en_test[en_test.label != \"no\"]])\n",
    "es_test = pd.concat([es_test_neg, es_test[es_test.label != 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.0', '1.0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train = en_train[[\"label\", \"text\"]]\n",
    "en_train['text'] = en_train['text'].str.lower()\n",
    "en_train['text'] = en_train['text'].str.replace('[^\\w\\s]','')\n",
    "en_train['text'] = en_train['text'].str.replace('\\n', ' ')\n",
    "en_train = en_train[~en_train.text.str.contains('^\\s+$', regex= True)]\n",
    "en_train['text'] = [re.sub(r\"\\s+\", \" \", x) for x in en_train['text'].tolist()]\n",
    "en_train[\"label\"] = en_train[\"label\"].astype(str)\n",
    "en_train = en_train[(en_train.text.str.split().str.len() >=2) & (en_train.text.str.split().str.len() <= 50)]\n",
    "set(en_train.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional if labels need to be fixed\n",
    "en_train[\"label\"] = [\"0\" if x == '0.0' else \"1\" for x in en_train.label.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create seed language splits\n",
    "train, validate = np.split(en_train.sample(frac=1), [int(0.8*len(en_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no', 'secrecy'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_test = en_test[[\"text\", \"label\"]]\n",
    "en_test['text'] = en_test['text'].str.lower()\n",
    "en_test['text'] = en_test['text'].str.replace('[^\\w\\s]','')\n",
    "en_test['text'] = en_test['text'].str.replace('\\n', ' ')\n",
    "en_test = en_test[~en_test.text.str.contains('^\\s+$', regex= True)]\n",
    "en_test['text'] = [re.sub(r\"\\s+\", \" \", x) for x in en_test['text'].tolist()]\n",
    "en_test[\"label\"] = en_test[\"label\"].astype(str)\n",
    "en_test = en_test[(en_test.text.str.split().str.len() >=2) & (en_test.text.str.split().str.len() <= 50)]\n",
    "set(en_test.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test[\"label\"] = [\"0\" if x == \"no\" else \"1\" for x in en_test.label.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0', '1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_test = es_test[[\"text\", \"label\"]]\n",
    "es_test['text'] = es_test['text'].str.lower()\n",
    "es_test['text'] = es_test['text'].str.replace('[^\\w\\s]','')\n",
    "es_test['text'] = es_test['text'].str.replace('\\n', ' ')\n",
    "es_test = es_test[~es_test.text.str.contains('^\\s+$', regex= True)]\n",
    "es_test['text'] = [re.sub(r\"\\s+\", \" \", x) for x in es_test['text'].tolist()]\n",
    "es_test[\"label\"] = es_test[\"label\"].astype(str)\n",
    "es_test = es_test[(es_test.text.str.split().str.len() >=2) & (es_test.text.str.split().str.len() <= 50)]\n",
    "set(es_test.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'0', '1'}, {'0', '1'}, {'0', '1'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(en_train.label.tolist()), set(en_test.label.tolist()), set(es_test.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data_hard_negatives/\"\n",
    "\n",
    "with open(WORKING_DIR + DATA_DIR + \"train.txt.\" + TARGET_LANG, \"w\") as fl:\n",
    "    fl.write(\"\\n\".join(train.text.tolist()))\n",
    "    \n",
    "with open(WORKING_DIR + DATA_DIR + \"train.lbl.\" + TARGET_LANG, \"w\") as fl:\n",
    "    fl.write(\"\\n\".join(train.label.tolist()))\n",
    "\n",
    "with open(WORKING_DIR + DATA_DIR + \"dev.txt.\" + TARGET_LANG, \"w\") as fl:\n",
    "    fl.write(\"\\n\".join(validate.text.tolist()))\n",
    "    \n",
    "with open(WORKING_DIR + DATA_DIR + \"dev.lbl.\" + TARGET_LANG, \"w\") as fl:\n",
    "    fl.write(\"\\n\".join(validate.label.tolist()))\n",
    "\n",
    "with open(WORKING_DIR + DATA_DIR + \"test.txt.\" + TARGET_LANG, \"w\") as fl:\n",
    "    fl.write(\"\\n\".join(en_test.text.tolist()))\n",
    "    \n",
    "with open(WORKING_DIR + DATA_DIR + \"test.lbl.\" + TARGET_LANG, \"w\") as fl:\n",
    "    fl.write(\"\\n\".join(en_test.label.tolist()))\n",
    "\n",
    "with open(WORKING_DIR + DATA_DIR + \"test.txt.\" + TEST_LANG, \"w\") as fl:\n",
    "    fl.write(\"\\n\".join(es_test.text.tolist()))\n",
    "    \n",
    "with open(WORKING_DIR + DATA_DIR + \"test.lbl.\" + TEST_LANG, \"w\") as fl:\n",
    "    fl.write(\"\\n\".join(es_test.label.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
