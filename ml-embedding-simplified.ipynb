{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding training and testing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 09:23:30.044141: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "my_stderr = sys.stderr = open('errors.txt', 'w')  # redirect stderr to file\n",
    "get_ipython().log.handlers[0].stream = my_stderr  # log errors to new stderr\n",
    "get_ipython().log.setLevel(logging.INFO)  # errors are logged at info level\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import ipdb\n",
    "from tqdm import tqdm\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASER=\"LASER-master\"\n",
    "mldir = \"ml-training/SECRECY-EN/data\" # training data and embeddings are held here\n",
    "model_name = \"SECRECY-EN\"\n",
    "edir = mldir + \"/embed_simplified\" # location of laser script that that embeds to LASER SS\n",
    "#embedding_name = 'USE'\n",
    "embedding_name = 'USEm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def USE(txt_list, use_embedder):\n",
    "    output = []\n",
    "    txt_df = pd.Series(txt_list)\n",
    "    batch_size = 124\n",
    "    for k,g in tqdm(txt_df.groupby(np.arange(len(txt_df))//batch_size)):\n",
    "        output.append(use_embedder(g.tolist()).numpy())\n",
    "    output = np.concatenate(output, axis=0).flatten()\n",
    "    print(output.shape)\n",
    "    print(output.min())\n",
    "    print(output.max())\n",
    "    print('\\n')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing:\n",
      "(5427200,)\n",
      "-0.24683398\n",
      "0.2476417\n",
      "\n",
      "\n",
      "float32 (5427200,)\n",
      "(1357312,)\n",
      "-0.22874442\n",
      "0.2429925\n",
      "\n",
      "\n",
      "float32 (1357312,)\n",
      "(17886208,)\n",
      "-0.23657498\n",
      "0.26058263\n",
      "\n",
      "\n",
      "float32 (17886208,)\n",
      "\n",
      "Processing:\n",
      "(2135040,)\n",
      "-0.25308377\n",
      "0.29279864\n",
      "\n",
      "\n",
      "float32 (2135040,)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(edir):\n",
    "    os.mkdir(edir)\n",
    "\n",
    "#lang=\"en\"\n",
    "for lang in ['en','es']:\n",
    "    print('\\nProcessing:')\n",
    "    #embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
    "\n",
    "    for part in ('train', 'dev', 'test'):\n",
    "        # Spanish only exists for test\n",
    "        if (lang=='es') & (part!='test'):\n",
    "            continue\n",
    "        cfname = os.path.join(mldir, part)\n",
    "        if os.path.exists(cfname + '.' + embedding_name + '.enc.' + lang): # embedding_name\n",
    "            print(cfname + '.' + embedding_name + '.enc.' + lang + ' Exists')\n",
    "        txt = []\n",
    "        \n",
    "        # copy original files to embed directory, then embed it\n",
    "        os.system('cp ' + cfname + '.txt.' + lang + ' ' + os.path.join(edir, part) + '.txt.' + lang)\n",
    "        os.system('cp ' + cfname + '.lbl.' + lang + ' ' + os.path.join(edir, part) + '.lbl.' + lang)\n",
    "        \n",
    "        # embed file in embed directory\n",
    "        with open(cfname + '.txt.' + lang) as f:\n",
    "            for l in f:\n",
    "                txt.append(l)\n",
    "        use_np = USE(txt, embed)\n",
    "        print(use_np.dtype, use_np.shape)\n",
    "        use_np.tofile(edir + \"/\" + part + '.' + embedding_name + '.enc.' + lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MultiLingualEmbeddings]",
   "language": "python",
   "name": "conda-env-MultiLingualEmbeddings-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
